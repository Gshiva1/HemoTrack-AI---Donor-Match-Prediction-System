{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ppphvf_hbzMG",
        "outputId": "368715d9-e97f-4fb3-bbac-5b7a6276797d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faker in /usr/local/lib/python3.11/dist-packages (37.5.3)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.48.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.5.1)\n",
            "Requirement already satisfied: faker in /usr/local/lib/python3.11/dist-packages (37.5.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (1.48.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.7.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.26.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install faker\n",
        "!pip install pandas scikit-learn imbalanced-learn streamlit joblib faker\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Step 1: Create Synthetic Dataset (CSV)\n"
      ],
      "metadata": {
        "id": "xXRgsGJ5ceFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from faker import Faker\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "blood_groups = ['A+', 'A-', 'B+', 'B-', 'AB+', 'AB-', 'O+', 'O-']\n",
        "data = []\n",
        "\n",
        "for i in range(1000):\n",
        "    data.append({\n",
        "        'Donor_ID': f'DR{i+1:04d}',\n",
        "        'Name': fake.name(),\n",
        "        'Blood_Group': random.choice(blood_groups),\n",
        "        'Location': fake.city(),\n",
        "        'Latitude': fake.latitude(),\n",
        "        'Longitude': fake.longitude(),\n",
        "        'Last_Donation_Days_Ago': random.randint(0, 180),\n",
        "        'Availability': random.choice(['Yes', 'No']),\n",
        "        'Screened': random.choice(['Yes', 'No']),\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv('donor_dataset.csv', index=False)\n"
      ],
      "metadata": {
        "id": "l9VEHzREcVVK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recommended Match (Based on Rules)rule based prediction"
      ],
      "metadata": {
        "id": "P9TwOB3N3zJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Rule-Based Matching Function\n",
        "def is_donor_match(blood_group, last_donated_days, availability, screened):\n",
        "    if availability.lower() != \"yes\":\n",
        "        return 0\n",
        "    if screened.lower() != \"yes\":\n",
        "        return 0\n",
        "    if last_donated_days < 56:  # Donors are advised to wait 56 days\n",
        "        return 0\n",
        "    if blood_group.upper() not in ['A+', 'B+', 'O+', 'AB+']:\n",
        "        return 0  # Only consider common compatible groups (basic rule)\n",
        "    return 1\n",
        "\n",
        "# Sample usage\n",
        "sample_donors = pd.DataFrame({\n",
        "    'BloodGroup': ['A+', 'B-', 'O+', 'AB+', 'A-'],\n",
        "    'LastDonationDays': [60, 20, 90, 100, 70],\n",
        "    'Availability': ['Yes', 'No', 'Yes', 'Yes', 'Yes'],\n",
        "    'Screened': ['Yes', 'Yes', 'No', 'Yes', 'Yes']\n",
        "})\n",
        "\n",
        "# Apply rules to each row\n",
        "sample_donors['Match'] = sample_donors.apply(\n",
        "    lambda row: is_donor_match(row['BloodGroup'], row['LastDonationDays'], row['Availability'], row['Screened']),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "print(\"Rules-Based Prediction:\")\n",
        "print(sample_donors)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOc4xkfw3p-I",
        "outputId": "27c4e0a2-4352-4009-bf50-4076d3e474a6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rules-Based Prediction:\n",
            "  BloodGroup  LastDonationDays Availability Screened  Match\n",
            "0         A+                60          Yes      Yes      1\n",
            "1         B-                20           No      Yes      0\n",
            "2         O+                90          Yes       No      0\n",
            "3        AB+               100          Yes      Yes      1\n",
            "4         A-                70          Yes      Yes      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your CSV\n",
        "df = pd.read_csv('donor_dataset.csv')\n",
        "\n",
        "# Define blood compatibility\n",
        "blood_compatibility = {\n",
        "    'A+': ['A+', 'A-', 'O+', 'O-'],\n",
        "    'B+': ['B+', 'B-', 'O+', 'O-'],\n",
        "    'AB+': ['A+', 'A-', 'B+', 'B-', 'AB+', 'AB-', 'O+', 'O-'],\n",
        "    'O+': ['O+', 'O-'],\n",
        "    'A-': ['A-', 'O-'],\n",
        "    'B-': ['B-', 'O-'],\n",
        "    'AB-': ['A-', 'B-', 'AB-', 'O-'],\n",
        "    'O-': ['O-']\n",
        "}\n",
        "\n",
        "# Rule-based function\n",
        "def is_match(donor, recipient_blood_group='A+'):\n",
        "    return (donor['Blood_Group'] in blood_compatibility[recipient_blood_group]) and \\\n",
        "           (donor['Availability'] == 'Yes') and \\\n",
        "           (donor['Screened'] == 'Yes') and \\\n",
        "           (donor['Last_Donation_Days_Ago'] > 90)\n",
        "\n",
        "# Apply function\n",
        "df['Match'] = df.apply(lambda row: int(is_match(row, 'A+')), axis=1)\n",
        "\n",
        "# Save updated CSV with 'Match' column\n",
        "df.to_csv('donor_dataset_with_match.csv', index=False)\n",
        "\n",
        "# Preview match count\n",
        "print(\"Total Matched Donors:\", df['Match'].sum())\n",
        "print(df[['Donor_ID', 'Blood_Group', 'Availability', 'Screened', 'Last_Donation_Days_Ago', 'Match']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF1Jomknf8lc",
        "outputId": "43d4960c-afb0-4534-9468-fb51891abb3e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Matched Donors: 60\n",
            "  Donor_ID Blood_Group Availability Screened  Last_Donation_Days_Ago  Match\n",
            "0   DR0001          A-          Yes      Yes                     160      1\n",
            "1   DR0002          O+           No      Yes                     139      0\n",
            "2   DR0003          A-          Yes      Yes                       8      0\n",
            "3   DR0004          O-           No      Yes                      47      0\n",
            "4   DR0005          B-          Yes      Yes                     137      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Build a Machine Learning Classifier"
      ],
      "metadata": {
        "id": "vWUFWRaldnC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Prepare labeled dataset (simulate Match column)\n",
        "import numpy as np\n",
        "\n",
        "df['Match'] = df.apply(\n",
        "    lambda row: 1 if is_match(row, recipient_blood_group='A+') else 0,\n",
        "    axis=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "UlA28D-cde9m"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "sample model accuracy\n"
      ],
      "metadata": {
        "id": "_KNB_4ZD3Zvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('donor_dataset_with_match.csv')\n",
        "\n",
        "# Label encode categorical features\n",
        "le = LabelEncoder()\n",
        "for col in ['Blood_Group', 'Availability', 'Screened']:\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Features and labels\n",
        "X = df[['Blood_Group', 'Last_Donation_Days_Ago', 'Availability', 'Screened']]\n",
        "y = df['Match']\n",
        "\n",
        "# Check class balance\n",
        "print(\"Original Match value counts:\\n\", y.value_counts())\n",
        "\n",
        "# Apply SMOTE for balancing\n",
        "sm = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = sm.fit_resample(X, y)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_resampled, y_resampled, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the donor dataset\n",
        "df = pd.read_csv(\"donor_dataset_with_match.csv\")\n",
        "\n",
        "# Load the trained model\n",
        "model = joblib.load(\"donor_match_model.pkl\")\n",
        "\n",
        "# Streamlit App Title\n",
        "st.title(\"HemoTrack AI - Donor Prediction System\")\n",
        "\n",
        "# Recipient blood group selection\n",
        "blood_groups = ['A+', 'A-', 'B+', 'B-', 'AB+', 'AB-', 'O+', 'O-']\n",
        "recipient_blood_group = st.selectbox(\"Select Recipient's Blood Group\", blood_groups)\n",
        "\n",
        "# Toggle mode\n",
        "mode = st.radio(\"Choose Matching Method\", ['Rule-Based', 'ML Model'])\n",
        "\n",
        "# Define compatibility\n",
        "blood_compatibility = {\n",
        "    'A+': ['A+', 'A-', 'O+', 'O-'],\n",
        "    'B+': ['B+', 'B-', 'O+', 'O-'],\n",
        "    'AB+': blood_groups,\n",
        "    'O+': ['O+', 'O-'],\n",
        "    'A-': ['A-', 'O-'],\n",
        "    'B-': ['B-', 'O-'],\n",
        "    'AB-': ['AB-', 'A-', 'B-', 'O-'],\n",
        "    'O-': ['O-']\n",
        "}\n",
        "\n",
        "# Rule-based function\n",
        "def is_match(donor):\n",
        "    return (donor['Blood_Group'] in blood_compatibility[recipient_blood_group]) and \\\n",
        "           (donor['Availability'] == 'Yes') and \\\n",
        "           (donor['Screened'] == 'Yes') and \\\n",
        "           (donor['Last_Donation_Days_Ago'] > 90)\n",
        "\n",
        "# Process on button click\n",
        "if st.button(\"Find Matching Donors\"):\n",
        "    if mode == 'Rule-Based':\n",
        "        df['Rule_Match'] = df.apply(is_match, axis=1)\n",
        "        matched = df[df['Rule_Match'] == True]\n",
        "    else:\n",
        "        # Prepare features\n",
        "        le = LabelEncoder()\n",
        "        temp_df = df.copy()\n",
        "        for col in ['Blood_Group', 'Availability', 'Screened']:\n",
        "            temp_df[col] = le.fit_transform(temp_df[col])\n",
        "\n",
        "        X = temp_df[['Blood_Group', 'Last_Donation_Days_Ago', 'Availability', 'Screened']]\n",
        "        df['ML_Predicted_Match'] = model.predict(X)\n",
        "        matched = df[df['ML_Predicted_Match'] == 1]\n",
        "\n",
        "    st.success(f\"Found {len(matched)} matched donor(s)\")\n",
        "    st.dataframe(matched[['Donor_ID', 'Name', 'Blood_Group', 'Location', 'Last_Donation_Days_Ago']])\n",
        "\n",
        "    # Optional: Download filtered results\n",
        "    st.download_button(\n",
        "        label=\"Download Matched Donors CSV\",\n",
        "        data=matched.to_csv(index=False).encode('utf-8'),\n",
        "        file_name='matched_donors.csv',\n",
        "        mime='text/csv'\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UuQ9lLOejfp",
        "outputId": "4ebb05ec-b38c-4ae1-9003-f9a22b82e86c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Match value counts:\n",
            " Match\n",
            "0    940\n",
            "1     60\n",
            "Name: count, dtype: int64\n",
            "Accuracy: 0.9707446808510638\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.96      0.97       182\n",
            "           1       0.96      0.98      0.97       194\n",
            "\n",
            "    accuracy                           0.97       376\n",
            "   macro avg       0.97      0.97      0.97       376\n",
            "weighted avg       0.97      0.97      0.97       376\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-08-06 14:35:11.844 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-06 14:35:12.209 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-08-06 14:35:12.211 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-06 14:35:12.214 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-06 14:35:12.215 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-06 14:35:12.217 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-06 14:35:12.219 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-06 14:35:12.221 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-06 14:35:12.223 Session state does not function when running a script without `streamlit run`\n",
            "2025-08-06 14:35:12.225 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-06 14:35:12.227 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-06 14:35:12.229 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-06 14:35:12.231 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-06 14:35:12.233 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-06 14:35:12.235 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-06 14:35:12.237 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-06 14:35:12.240 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-06 14:35:12.241 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-06 14:35:12.242 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-06 14:35:12.244 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-06 14:35:12.245 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-06 14:35:12.247 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-06 14:35:12.248 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-06 14:35:12.249 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-06 14:35:12.249 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RNKF1v4UOgm",
        "outputId": "0786dc66-a131-41c6-b556-f1bc36722a09"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.48.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.3.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (1.48.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.7.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok --quiet\n"
      ],
      "metadata": {
        "id": "jnJYrHadVFYz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_and_save_model.py(Random forest)| donor_ml_training.py (AI-Powered Match (Smarter Prediction)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mrHb0BOk1Kda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# File: train_and_save_model.py\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import joblib\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('donor_dataset_with_match.csv')\n",
        "\n",
        "# Label encode categorical features\n",
        "le_bg = LabelEncoder()\n",
        "le_avail = LabelEncoder()\n",
        "le_screened = LabelEncoder()\n",
        "\n",
        "df['Blood_Group'] = le_bg.fit_transform(df['Blood_Group'])\n",
        "df['Availability'] = le_avail.fit_transform(df['Availability'])\n",
        "df['Screened'] = le_screened.fit_transform(df['Screened'])\n",
        "\n",
        "# Save encoders\n",
        "joblib.dump(le_bg, 'encoder_blood_group.pkl')\n",
        "joblib.dump(le_avail, 'encoder_availability.pkl')\n",
        "joblib.dump(le_screened, 'encoder_screened.pkl')\n",
        "\n",
        "# Features and labels\n",
        "X = df[['Blood_Group', 'Last_Donation_Days_Ago', 'Availability', 'Screened']]\n",
        "y = df['Match']\n",
        "\n",
        "# SMOTE for balancing\n",
        "sm = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = sm.fit_resample(X, y)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save model\n",
        "joblib.dump(model, 'donor_match_model.pkl')\n",
        "\n",
        "# Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ifu1kdNtIGe",
        "outputId": "bde59ef7-858b-46ee-a75b-a36b03e82fc4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9707446808510638\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.96      0.97       182\n",
            "           1       0.96      0.98      0.97       194\n",
            "\n",
            "    accuracy                           0.97       376\n",
            "   macro avg       0.97      0.97      0.97       376\n",
            "weighted avg       0.97      0.97      0.97       376\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "APP CODE (app.py)"
      ],
      "metadata": {
        "id": "ki1e0c2L1RRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "app_code = \"\"\"import streamlit as st\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "# Load the ML model and encoders\n",
        "model = joblib.load(\"donor_match_model.pkl\")\n",
        "le_bg = joblib.load(\"encoder_blood_group.pkl\")\n",
        "le_avail = joblib.load(\"encoder_availability.pkl\")\n",
        "le_screened = joblib.load(\"encoder_screened.pkl\")\n",
        "\n",
        "# Load donor dataset\n",
        "df = pd.read_csv(\"donor_dataset_with_match.csv\")\n",
        "\n",
        "# Streamlit UI\n",
        "st.set_page_config(page_title=\"HemoTrack AI - Donor Matcher\", layout=\"centered\")\n",
        "st.title(\"🩸 HemoTrack AI - Donor Match Prediction System\")\n",
        "\n",
        "# Select recipient blood group\n",
        "blood_groups = le_bg.classes_\n",
        "recipient_blood_group = st.selectbox(\"🧬 Select Recipient's Blood Group\", blood_groups)\n",
        "\n",
        "# Select matching method\n",
        "mode = st.radio(\"🔎 Choose Match Type\", [\n",
        "    \"Recommended Match (Based on Rules)\",\n",
        "    \"AI-Powered Match (Smarter Prediction)\"\n",
        "])\n",
        "\n",
        "# Blood group compatibility map\n",
        "blood_compatibility = {\n",
        "    'A+': ['A+', 'A-', 'O+', 'O-'],\n",
        "    'B+': ['B+', 'B-', 'O+', 'O-'],\n",
        "    'AB+': list(blood_groups),\n",
        "    'O+': ['O+', 'O-'],\n",
        "    'A-': ['A-', 'O-'],\n",
        "    'B-': ['B-', 'O-'],\n",
        "    'AB-': ['AB-', 'A-', 'B-', 'O-'],\n",
        "    'O-': ['O-']\n",
        "}\n",
        "\n",
        "# Rule-based match logic\n",
        "def is_match(donor):\n",
        "    return (\n",
        "        donor['Blood_Group'] in blood_compatibility[recipient_blood_group] and\n",
        "        donor['Availability'] == 'Yes' and\n",
        "        donor['Screened'] == 'Yes' and\n",
        "        donor['Last_Donation_Days_Ago'] > 90\n",
        "    )\n",
        "\n",
        "# Match button\n",
        "if st.button(\"🔍 Find Matching Donors\"):\n",
        "    if \"Rule-Based\" in mode:\n",
        "        matches = df[df.apply(is_match, axis=1)]\n",
        "    else:\n",
        "        temp_df = df.copy()\n",
        "\n",
        "        # Encode features\n",
        "        temp_df['Blood_Group'] = le_bg.transform(temp_df['Blood_Group'])\n",
        "        temp_df['Availability'] = le_avail.transform(temp_df['Availability'])\n",
        "        temp_df['Screened'] = le_screened.transform(temp_df['Screened'])\n",
        "\n",
        "        # Predict match\n",
        "        X = temp_df[['Blood_Group', 'Last_Donation_Days_Ago', 'Availability', 'Screened']]\n",
        "        df['ML_Predicted_Match'] = model.predict(X)\n",
        "        matches = df[df['ML_Predicted_Match'] == 1]\n",
        "\n",
        "    # Display results\n",
        "    st.success(f\"✅ Found {len(matches)} matching donor(s)\")\n",
        "    st.dataframe(matches[['Donor_ID', 'Name', 'Blood_Group', 'Location', 'Last_Donation_Days_Ago']])\n",
        "\n",
        "    # Download results\n",
        "    st.download_button(\n",
        "        \"📥 Download Matching Donors\",\n",
        "        matches.to_csv(index=False).encode('utf-8'),\n",
        "        file_name=\"matched_donors.csv\",\n",
        "        mime=\"text/csv\"\n",
        "    )\n",
        "\"\"\"\n",
        "\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(app_code)\n"
      ],
      "metadata": {
        "id": "zaSAVOItxD5s"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "!ngrok authtoken 30uwePinxWfVCG4RUnUMcdcpwo9_6Ykw9j2kFqSeQZhFyQV4x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2KtJc8qxjla",
        "outputId": "cc25c311-bad6-4314-abe6-617c24b67303"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "launch_streamlit_with_ngrok.py\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "SUdTlPq71ZC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import threading\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Install if not already\n",
        "os.system(\"pip install streamlit pyngrok --quiet\")\n",
        "\n",
        "# Set your ngrok authtoken here (get yours from https://dashboard.ngrok.com/get-started/your-authtoken)\n",
        "NGROK_AUTH_TOKEN = \"30uwePinxWfVCG4RUnUMcdcpwo9_6Ykw9j2kFqSeQZhFyQV4x\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# Start Streamlit app in a thread\n",
        "def run_streamlit():\n",
        "    os.system(\"streamlit run app.py\")\n",
        "\n",
        "thread = threading.Thread(target=run_streamlit)\n",
        "thread.start()\n",
        "\n",
        "# Wait a bit for the server to start\n",
        "time.sleep(5)\n",
        "\n",
        "# Connect ngrok HTTP tunnel to port 8501\n",
        "public_url = ngrok.connect(\"http://localhost:8501\", \"http\")\n",
        "print(f\"✅ Streamlit app is live at: {public_url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zNUWYtwz1cd",
        "outputId": "2b57b983-25a4-4fb9-c76e-eeefb256dad0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Streamlit app is live at: NgrokTunnel: \"https://0cd518bc5ec1.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tke5pOAh0GHK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}